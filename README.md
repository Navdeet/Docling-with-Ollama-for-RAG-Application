## Introduction

Welcome to **Docling with Ollama**! This tool is combines the best of both Docling for document parsing and Ollama for local models. It enables you to use Docling and Ollama for RAG over PDF files (or any other supported file format) with LlamaIndex. It provides you a nice clean Streamlit GUI to chat with your own documents locally.

## Prerequisites

Before you begin, ensure you have met the following requirements:

- **Python**: Make sure you have Python version >3.10 installed. You can download it from [python.org](https://www.python.org/downloads/).
- **Pip**: Ensure pip is installed to manage Python packages. It usually comes with Python.
- **Virtual Environment**: It's recommended to use a virtual environment to manage dependencies. I prefer Conda.
- **Ollama**: Make sure Ollama is installed and llama3.2 model is downloaded with ollama pull llama3.2 command

